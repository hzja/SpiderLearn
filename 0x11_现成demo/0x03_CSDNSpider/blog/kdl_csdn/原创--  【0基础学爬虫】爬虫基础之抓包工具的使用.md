# 原创
：  【0基础学爬虫】爬虫基础之抓包工具的使用

# 【0基础学爬虫】爬虫基础之抓包工具的使用

> 
大数据时代，各行各业对数据采集的需求日益增多，网络爬虫的运用也更为广泛，越来越多的人开始学习网络爬虫这项技术，K哥爬虫此前已经推出不少爬虫进阶、逆向相关文章，为实现从易到难全方位覆盖，特设【0基础学爬虫】专栏，帮助小白快速入门爬虫，本期为抓包工具的使用。


### 抓包工具概述

抓包工具，顾名思义，就是抓取网络数据包信息的工具。抓包工具最初主要应用于测试工作中，通过抓包工具查看网络数据包，并进行分析，来定位数据传输中的问题。随着不断发展，抓包工具的功能不断拓展，在网络数据传输中能够将获取到的数据包进行重发、编辑、替换等操作。作为爬虫开发者，我们需要模拟用户的真实请求来获取数据，所以我们需要了解目标网站交互中的数据信息是如何传输的，以及详细的请求信息、传递信息、接收信息。因此掌握各抓包工具的使用是一项必备的技能。

### 常见抓包工具及工作原理

目前流行的抓包工具有很多，这里只介绍实际开发中最为常见的。<br/> 常见的抓包工具可以分为两种：

1、抓取应用层的HTTP/HTTPS协议包，通过中间人代理截取协议包，如：Fiddler，Charles。

以Fiddler为例，此类抓包工具通过代理某个端口，拦截经过该端口的通信协议，并对传输数据进行解析展示，使用也起来非常简单。对于HTTP请求，数据传输都是明文，抓包工具可以直接看到数据报文。但HTTPS请求在HTTP基础上多了一层SSL/TLS协议，在数据传输中采用了双向加密，对于传输中的数据包需要密钥来进行解密，因此抓包工具即使拦截到了数据包，也无法对数据进行解析。因此Fiddler、Charles在使用前需要安装证书。

2、抓取传输层的TCP/UDP协议，在网卡的链路层截取数据包，如：Wireshark。

### F12开发者工具

F12开发者工具是在爬虫开发中最常使用到的工具，它可以被用来查看网页HTML元素、调试网页、抓包等。

以谷歌开发者工具为例，打开F12工具可以看到此界面。

工具顶部有一些功能选项，在实际开发中，我们会经常用到以下几种：

> 
元素（Elements）：用来查看、修改HTML元素，修改CSS属性，查看样式，监听事件等
控制台（console）：记录异常信息，执行JS代码
源代码（Sources）：查看网页源码、设置断点、本地替换、运行JS脚本
网络（Network）：监听请求资源


本次主要介绍网络（Network）面板。

关于网络面板，我们需要知道一些基本的功能按钮。

从左到右有六个选项：

**1. 录制按钮：** 红色代表正在录制网络活动，会持续监听该网页的网络活动，灰色代表停止录制。

**2. 清除按钮：** 会将录制到的网络活动清除。

**3. 过滤按钮：** 可以筛选出URL中包含输入信息的请求，也可以选择根据请求类型进行筛选。

**4. 搜索按钮：** 可以搜索出包含输入信息的所有请求。

**5. 保留日志：** 勾选时，当页面重新加载时不会清空上一次加载时的请求信息，未勾选时页面重新加载时会自动清除上一次加载时的请求信息。建议勾选。

**6. 停用缓存：** 建议勾选。

#### 使用F12抓包

使用开发者工具进行抓包十分简单，只需要进行简单的操作。

1、打开F12开发者工具。

2、打开目标网址。

即可完成抓包操作。

#### 请求列表

请求列表里面包含了与网站交互中每个请求资源的信息。

点开任意资源，数据信息主要分为5种：

**1. 常规信息：** 常规信息中记录了请求网址、请求方法、请求状态码，通过常规信息可以了解请求是否成功。

**2. 响应头信息：** 响应头信息中记录了服务端响应的头信息。

**3. 请求头信息：** 请求头信息中记录了客户端发起请求时携带的头信息。

**4. 载荷信息：** 记录了请求时提交的数据。

**5. 响应信息：** 记录了服务端的响应信息。

F12开发者工具功能很强大，使用起来也非常便捷。但是也存在着很大的弊端：
1. 容易被网站检测，网站可以检测用户是否打开了F12，干扰开发者接下来的调试。1. 数据自动清空，浏览器为了减少资源信息的缓存，当一个资源被二次请求时，第一次的响应信息将会被清空。
因此在爬虫开发中，会用到更为强大的抓包工具。

### Fiddler的安装与使用

#### 下载与安装

可以在 [Fiddler官网](https://www.telerik.com/download/fiddler) 下载Fiddler经典版，下载时需要提交邮箱等资料。

安装过程很简单，这里就不做介绍。

#### 证书安装

安装完成后在安装目录中找到fiddler.exe运行。 如上文所述，Fiddler在使用前需要安装证书，否则无法抓到HTTPS包。

安装方法：Tools-&gt;Options-&gt;HTTPS<br/> <img alt="13" src="https://i-blog.csdnimg.cn/blog_migrate/8d24e63e49d5f6f6eba6d9092fa5ac4f.png"/>

勾选以上三个选项。点击Actions-Trust Root Certificate-Yes，信任证书。

导出证书到桌面，并打开谷歌浏览器-设置-安全-管理设备证书，将导出的证书导入到浏览器。

#### 面板

Fiddler内置了许多强大的功能，这里只介绍基本用法与常用功能。

###基本用法：

当我们需要对某个网站进行抓包时，只需要打开Fiddler工具，观察状态栏中的Capturing是否存在，存在则代表正在记录会话。选择All Processes捕获所有进程会话。打开网站后，Fiddler会自动的记录每条会话信息，会话列表中记录了Fiddler抓到的每条请求数据包，包含：

编号（按请求顺序编号）、HOST（请求主机名）、URL、Content-Type（响应数据类型）、Result（响应状态码）、Protocol（请求协议）、Body（字节数）、Caching（可缓存信息）、Process（发起请求的进程）、Comment（注释）、Custom（备注）。

请求信息栏和响应信息栏中记录了请求和响应时的详细信息。

#### 功能：

**AutoResponder（响应替换）：** 通常在逆向开发中，会遇到一些网站的加密算法代码是动态变化的或者经过了高度混淆，也可能在某段代码中对F12进行了检测，通过各种手段干扰我们对网站进行调试。遇到这种情况，我们就可以使用AutoResponder功能，AutoResponder可以拦截目标请求，将目标请求的响应内容进行修改。利用AutoResponder，我们可以将干扰我们调试的代码文件进行修改调整，方便之后的调试。
1. 将想要修改的请求拖入AutoResponder中1. 勾选Enable rules -&gt; Add Rule1. 点击Rule Editor框的第二栏，滑倒最下，选择Find a file，选择进行替换的文件1. Save 保存
保存完成后刷新就可以发现目标请求被替换了。

**重发：** 选中需要重发的请求，点击工具栏中的Replay即可。

**模拟请求：** 点击工具栏中的Composer，输入目标网址、请求头，选择请求方式，点击Execute即可发起一次模拟请求。

### Charles的使用

Charles与Fiddler的功能大同小异，但是Fiddler经典版不支持mac，Charles支持全系统，所以Charles算是Fiddler在mac系统中的一个替代品。所以只做简单介绍。

#### 下载与安装

在[Charles官网](https://www.charlesproxy.com/latest-release/) 下载对应的版本进行安装。

#### 配置

安装证书：进入Charles界面，点击Help -&gt; SLL Proxying -&gt; Install Charles Root Certificate -&gt; 安装证书 -&gt; 本地计算机 -&gt; 放入受信任的根证书颁发机构存储 -&gt; 完成

设置SSL代理：Proxy -&gt; Proxy Settings -&gt; 勾选如下选项

Proxy -&gt; SSL Proxying Settings

#### 使用

Charles抓包方式与Fiddler一致，打开目标网站Charles会自动抓取请求，点击Stop Recording可以停止抓包。

#### 面板

Charles面板与Fiddler有些区别，可以看到抓到的数据也详细一些。Charles有两种界面模式，可以选择Sequence，与Fildder比较接近。

#### 功能

**Filter** 根据关键字筛选请求

**重发** 选择请求，点击上方Repeat selected requests进行重发

**响应替换** 效果与Fildder的AutoResponder一致，右键需要进行响应替换的请求，选择Map Local，在Local path中选择替换的文件即可。

### 结语

上文中讲到了F12开发者工具、Fiddler、Charles这三款工具，正常爬虫工作中一些抓包需求这三款工具都能很好的解决，但随着爬虫的不断发展，反爬虫措施也不断增加。如近年来TLS指纹检测逐渐被应用到反爬虫中，在服务端与客户端建立连接时就可以检测到客户端是否是爬虫程序。通过Fiddler、Charlse这类抓包工具无法看到在建立TCP连接时传输了哪些信息，无法得知服务端是否可能检测了TLS指纹信息，因此需要用到如Wireshark等更为强大的抓包工具，所以爬虫开发者在提升自身水平的同时也需要掌握更为强大的工具，才能更好的解决问题。
